{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.11"
    },
    "colab": {
      "name": "SentimentClassification_RNNs_GloVe.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "TwCQeimytTVw",
        "enkonaCQtTWU",
        "7xTv17VNtTW9"
      ],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raj963/NLTK/blob/master/SentimentClassification_RNNs_GloVe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "4HSZsHAVtTTw",
        "colab_type": "text"
      },
      "source": [
        "## Sentiment Analysis of Reviews using RNNs in TensorFlow, with pre-built embeddings\n",
        "\n",
        "Modified from original code here: https://github.com/adeshpande3/LSTM-Sentiment-Analysis/blob/master/Oriole%20LSTM.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iw8jBnz_050R",
        "colab_type": "code",
        "outputId": "e7c34af2-1396-44f6-c53c-678e18a2e35d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "%tensorflow_version 1.3.0\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.3.0`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n",
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bDF8Xmd2Eon",
        "colab_type": "code",
        "outputId": "4424072a-a27a-47aa-da32-603535bac491",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "DBd04tT5tTT0",
        "colab_type": "text"
      },
      "source": [
        "#### Some imports to make code compatible with Python 2 as well as 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "x561gf0YtTT3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "UgBc9lxotTUH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import collections\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import tarfile\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "POq9lGIutTUT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from six.moves import urllib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "6__v-32YtTUf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib as mp\n",
        "import matplotlib.pyplot as plt\n",
        "# import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "l_YTtIZ4tTUs",
        "colab_type": "code",
        "outputId": "c3e83298-f82d-409a-c0d7-5667eea4bb84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "print(np.__version__)\n",
        "print(mp.__version__)\n",
        "print(tf.__version__)\n",
        "%tensorflow_version 1.3.0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.16.4\n",
            "2.2.4\n",
            "1.15.2\n",
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.3.0`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIBKEGJutTU7",
        "colab_type": "text"
      },
      "source": [
        "#### Download, unzip and untar files in an automated way"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "Rv7tGduqtTU9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DOWNLOADED_FILENAME = 'ImdbReviews.tar.gz'\n",
        "\n",
        "def download_file(url_path):\n",
        "    if not os.path.exists(DOWNLOADED_FILENAME):\n",
        "        filename, _ = urllib.request.urlretrieve(url_path, DOWNLOADED_FILENAME)\n",
        "\n",
        "    print('Found and verified file from this path: ', url_path)\n",
        "    print('Downloaded file: ', DOWNLOADED_FILENAME)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cY09Mm-TtTVF",
        "colab_type": "text"
      },
      "source": [
        "### Extract reviews and the corresponding positive and negative labels from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "Zye1Np4mtTVG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TOKEN_REGEX = re.compile(\"[^A-Za-z0-9 ]+\")\n",
        "\n",
        "\n",
        "def get_reviews(dirname, positive=True):\n",
        "    label = 1 if positive else 0\n",
        "\n",
        "    reviews = []\n",
        "    labels = []\n",
        "    for filename in os.listdir(dirname):\n",
        "        if filename.endswith(\".txt\"):\n",
        "            with open(dirname + filename, 'r+') as f:\n",
        "                review = f.read().decode('utf-8')\n",
        "                review = review.lower().replace(\"<br />\", \" \")\n",
        "                review = re.sub(TOKEN_REGEX, '', review)\n",
        "                \n",
        "                reviews.append(review)\n",
        "                labels.append(label)\n",
        "    \n",
        "    return reviews, labels           \n",
        "\n",
        "def extract_labels_data():\n",
        "    # If the file has not already been extracted\n",
        "    if not os.path.exists('aclImdb'):\n",
        "        with tarfile.open(DOWNLOADED_FILENAME) as tar:\n",
        "            tar.extractall()\n",
        "            tar.close()\n",
        "        \n",
        "    positive_reviews, positive_labels = get_reviews(\"aclImdb/train/pos/\", positive=True)\n",
        "    negative_reviews, negative_labels = get_reviews(\"aclImdb/train/neg/\", positive=False)\n",
        "\n",
        "    data = positive_reviews + negative_reviews\n",
        "    labels = positive_labels + negative_labels\n",
        "\n",
        "    return labels, data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "sM0-O5NWtTVK",
        "colab_type": "code",
        "outputId": "84e4ef82-a907-42d1-8704-ba756a9aa869",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "URL_PATH = 'http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
        "\n",
        "download_file(URL_PATH)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found and verified file from this path:  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Downloaded file:  ImdbReviews.tar.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "jo6HWg_StTVN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels, data = extract_labels_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "_r4jC2tttTVQ",
        "colab_type": "code",
        "outputId": "986ce65f-f603-4f40-9fd6-a017b42d9bff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "labels[:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 1, 1, 1, 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "jJjlSxl1tTVV",
        "colab_type": "code",
        "outputId": "a2d21f18-ffe2-4a3f-d48c-aab6e4183333",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "data[:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[u'this movie has been poorly received and badly reviewed the book by rebecca west was written in 1918 soon after wwi when shell shock and traumainduced amnesia were not clichs as the reviewers call it many books and movies later it is difficult to go back in time and live as the characters lived the realities of the time the war and the horror of the experience of the first war to use lethal gas the british class system the wife thought allimportant the hopeless spinster and the lover from the past still seen with the eyes of love being as young and as beautiful as she was 20 years ago  alan bates as the amnesiac soldier who will die if he isnt allowed to see margaret the girl of his youthful dreams builds on the devotion his character showed in far from the madding crowd having seen that performance it is possible to sense his strong romantic attachment to the girl who didnt live up to the familys and societys expectations margaret says we quarreled and as you rowed away you turned your face away from me so we know that the breakup was something that he instigated that it brought him shame but that he forgot the shame in his memory of his time with margaret i havent seen all his films but in the ones ive seen he imparts a strong masculinity which shines through even in this role as the disabled soldier  i didnt even recognize annmargaret at first and feel that her performance has been underrated not having read the book i wondered whether the child who died was the result of acting on a borderline incestuous feeling between jenny and chris though jenny does state that she is a cousin the way kitty keeps jenny in the nursery in the hairdrying scene the fact that kitty says she always dries her hair in that room seems more a way for kitty to keep the coals of anger hot than the orientation of the room to the sun or sentiment about a lost child and the statement she made that she wished chris hadnt felt it necessary to preserve the room exactly as it was when the child was alive made her seem uncaring toward the memory of the child also jenny is shown as living in the house in a subservient role as high society would have done to a fallen member at the time  having recently been the recipient of the intense fantasy of a lover nonsexualin keeping with the mores of the time from 50 years ago i couldrelate to margarets and her husbands dilemma i too was cast aside because i wasnt good enough for his family and upon his rediscovery of me via the internet i was burdened with helping him deal with his still very horrifying vietnam experiences and a marriage to a woman above his class whom he didnt believe he loved my husband like margarets was very understanding but the strain was very real the lover was finally able to reconcile his reallife situation with his fantasy of loving only me  i thought that it was a good decision to show very little of the reliving of the war experience that was happening in chriss mind i thought of mrs dalloway with the wwi soldier who acts out very violent memories and commits suicide versus chriss joy in his fantasy of margaret in contrast the actiona of the soldier in mrs dalloway seems overwrought  showing that the psychiatrist understood very little of what was happening to chris underlines what a major problem the whole group faced everyone seems to get their life back but was it the right choice',\n",
              " u'wow i loved this film it may not have had the funding and advertising that the latest hollywood blockbusters get but it packs twice the emotional punch the tale revolves around this one family from utah and its the connections between the people in the family that provide the film with its punch the main lead giovanni ribisi plays his part very well at no time does he leave you to believe that hes acting all his feelings its his brother elias koteas who stole the show for me though when the two were in scenes together they bounded their lines off of each other giving fantastic performances great cast great film',\n",
              " u'the second of the why we fight series concentrates on hitlers grab of the sudetanland and beyond as he makes a chump out of neville chamberlain and embarks on his conquest of europe   clearly meant as propaganda in its day this series over the test of time has become an informative documentary as well with most of the allied bias turning out to be historical fact the fuhrer hoists himself on his own petard with smug pronouncements before his people and the world as he says one thing and does another as his army moves east the czechs and austrians quickly capitulate but the poles put up an heroic struggle against overwhelming odds   the disparity between hitlers military might and chamberlain waving the munich treaty like a white flag declaring peace in our time to this day has durable propaganda qualities here in its original context it resonates even more powerfully as the darkness of world war ll sets in on europe leaving the american viewer with two options freedom or slavery in 1943 there was no evading this simple truth and the nazis strike makes its point effectively',\n",
              " u'no this is not no alice fairy tale my friends this wonderland fable is based on the true story of the gruesome bloody wonderland murders that occurred back in 80s california at the center of this bloodbath was no other than johnny wad himself yes john holmes daddy dingdong used other shotguns than his infamous 13inch milk machine besides being a legendary adult film actor holmes was as also a hardcore drug addict who befriended various hollywood junkies val kilmer was occasionally majestic as holmes but for once this holmes character did not milk it through completely the film possesses a whos who of supporting players josh lucas  dylan mcdermott as hollywood riffraffs  kate bosworth  lisa kudrow as the women in holmes life and eric bogosian as a menacing tinsletown entrepreneur these characters do play integral parts directly or indirectly in the wonderland murders out of this support group it was josh lucas who was the most fierce  impressive as the ardent ron launius lucas is gradually escalating into a major hollywood player with such charismatic turns in a beautiful mind  sweet home alabama director james cox sometime proved to be a bit of a coxsucker by displaying a vast amount of overextended scenes just like holmes famous organ holmes was eventually acquitted of the wonderland murders he died of complications from the aids virus wonderland will keep you wondering what really happened that bloody night and if holmes really laid out his weapon oops wrong holmes movie ok that is enough before i get penislized i mean penalized bye holmies  average',\n",
              " u'the invisible mouse is a delightful and different tom  jerrys cartoon it features the usual catmouse chases and battles but in a different way this time jerry accidentally falls in a bottle of invisible ink and is obviously very glad about this because he realizes that he can prepare lots of surprises for tom scare him torment him and confuse him  as much as it is weird its also very cool and funny to see what we cant see jerry invisible its amusing to see things lifting up in the air without seeing whos doing it we know who right  its like those things had a life of their own or even almost like a matter of ghosts its equally amusing to see jerry eating some candies and fruits while hes invisible i really like that instrumental music which plays when hes not visible  some of the best jokes on this short are when tom sees jerrys shadow and slams him and even when tom tries to slam him with a frying pan and jerry writes missed me i also like when jerry drinks toms chocolate milk becoming visible again and with a happy look on his face  overall this short has the basic ingredients needed for a classic cartoon humor entertainment fun and some nice artwork too']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "Rz0XHtSztTVZ",
        "colab_type": "code",
        "outputId": "f1c7ee85-4126-4c23-b55f-22cf62c16aed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(labels), len(data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 25000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "nvmAUlBrtTVc",
        "colab_type": "code",
        "outputId": "11055dd4-4cd4-4a19-d5af-0fc563f45895",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_document_length = max([len(x.split(\" \")) for x in data])\n",
        "print(max_document_length)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2470\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "IC6PL3H3tTVg",
        "colab_type": "text"
      },
      "source": [
        "### How many words to consider in each review?\n",
        "\n",
        "Majority of the reviews fall under 250 words. This a number we've chosen based on some analysis of the data:\n",
        "\n",
        "* Count the number of words in each file and divide by number of files to get an average i.e. **avg_words_per_file = total_words / num_files**\n",
        "* Plot the words per file on matplot lib and try find a number which includes a majority of files\n",
        "\n",
        "Word embeddings all have the same dimensionality which you can specify. A document is a vector of word embeddings (one dbpedia instance is a document in this case)\n",
        "\n",
        "* Each document should be of the **same length**, documents longer than the MAX_SEQUENCE_LENGTH are truncated to this length\n",
        "* The other documents will be **padded** by a special symbol to be the same max length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "DMlfVMKbtTVg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_SEQUENCE_LENGTH = 250"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kVyWsEetTVj",
        "colab_type": "text"
      },
      "source": [
        "### Use a pre-trained model for embeddings\n",
        "\n",
        "Instead of training our model on our own dataset we will use a pre-trained model.\n",
        "\n",
        "This is much better because these word vectors will be more generalized as they have been trained on a different dataset. These embeddings are trained using GloVe, a vector generation model very simalar to word2vec. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "HwrQo4RatTVk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = np.load('wordsList.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "hSsR0hIPtTVn",
        "colab_type": "code",
        "outputId": "3c709220-c041-43c8-bd2c-fe0a4ff82e54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "words[:5], len(words)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['0', ',', '.', 'of', 'to'], dtype='|S68'), 400000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aWcTVuatTVt",
        "colab_type": "text"
      },
      "source": [
        "### Map every word to a unique index\n",
        "\n",
        "The words are in the order and the position of the word in the word list is its index."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "yDTbwd2RtTVt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_word_index_dictionary(words):\n",
        "    \n",
        "    dictionary = {}\n",
        "    \n",
        "    index = 0\n",
        "    for word in words:\n",
        "        dictionary[word] = index\n",
        "        index += 1\n",
        "    \n",
        "    return dictionary\n",
        "\n",
        "dictionary = get_word_index_dictionary(words)        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwCQeimytTVw",
        "colab_type": "text"
      },
      "source": [
        "#### The most common words have lower index values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "mldGXEITtTVx",
        "colab_type": "code",
        "outputId": "ff59123d-ff9b-46ae-afe7-dd7becfeb9df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dictionary['and'], dictionary['this'], dictionary['together'], dictionary['supreme']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 37, 600, 1399)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Q2-F1gFtTV0",
        "colab_type": "text"
      },
      "source": [
        "### Convert the sentences so they're represented in the form of word indexes\n",
        "\n",
        "Use the word index mapping that we created earlier in order to look up the index for individual words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "o7HAC9T1tTV0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "review_ids = []\n",
        "\n",
        "def convert_reviews_to_ids(data, words):\n",
        "    words_list = words.tolist()\n",
        "\n",
        "    progress = 0\n",
        "    for review in data:\n",
        "        review_id = []\n",
        "        \n",
        "        index = 0\n",
        "        for word in review:\n",
        "            if index >= MAX_SEQUENCE_LENGTH:\n",
        "                break;\n",
        "            \n",
        "            try:\n",
        "                review_id.append(dictionary[word])\n",
        "            except KeyError:\n",
        "                review_id.append(0)\n",
        "            \n",
        "            index += 1\n",
        "        if len(review_id) < MAX_SEQUENCE_LENGTH:\n",
        "            review_id = np.pad(review_id, (0, MAX_SEQUENCE_LENGTH - index), 'constant')\n",
        "\n",
        "        review_ids.append(np.array(review_id))\n",
        "        progress += 1\n",
        "        \n",
        "        if progress % 1000 == 0:\n",
        "            print(\"Completed: \", progress)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-z2ufvuAtTV3",
        "colab_type": "code",
        "outputId": "5a336ab8-6ec0-4765-c1e0-d968e6956370",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "source": [
        "convert_reviews_to_ids(data, words)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Completed:  1000\n",
            "Completed:  2000\n",
            "Completed:  3000\n",
            "Completed:  4000\n",
            "Completed:  5000\n",
            "Completed:  6000\n",
            "Completed:  7000\n",
            "Completed:  8000\n",
            "Completed:  9000\n",
            "Completed:  10000\n",
            "Completed:  11000\n",
            "Completed:  12000\n",
            "Completed:  13000\n",
            "Completed:  14000\n",
            "Completed:  15000\n",
            "Completed:  16000\n",
            "Completed:  17000\n",
            "Completed:  18000\n",
            "Completed:  19000\n",
            "Completed:  20000\n",
            "Completed:  21000\n",
            "Completed:  22000\n",
            "Completed:  23000\n",
            "Completed:  24000\n",
            "Completed:  25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "zYxS3Eo-tTV6",
        "colab_type": "code",
        "outputId": "b4016477-83c7-45a8-8dca-1b8bf3f365a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "source": [
        "review_ids[19825]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3410, 1911,    7, 3814, 2159, 1110, 1968,    0, 2159, 5918,   41,\n",
              "       1534,    0, 1534, 1110, 1110, 1993, 1534,    0, 5025,   41, 4652,\n",
              "       1110,    0,    7,    0, 3410, 4868, 4868, 1968,    0,   41, 1968,\n",
              "       1110,    7,    0, 1534, 2159, 1110, 2404, 1110,    0, 1993,    7,\n",
              "       1911, 2159,   41, 3814,    0, 3410, 4868, 5025, 1968,   41, 1110,\n",
              "          0, 5918,    7, 5140, 3814,    0,    7, 3814, 1968,    0, 6891,\n",
              "       4868, 5918, 3814,    0, 1864, 5025, 1110, 1110, 1534, 1110,    0,\n",
              "         41, 3814,    0,    7,    0, 3814, 1110,   41, 5025,    0, 1534,\n",
              "         41, 1993, 4868, 3814,    0, 1864, 4868, 1993, 1110, 1968, 3524,\n",
              "          0, 5140, 5918, 1110, 1911, 1110,    0, 1864,    7, 3814,    0,\n",
              "       3524, 4868, 6479,    0, 3410, 4868,    0, 5140, 1911, 4868, 3814,\n",
              "       3410,    0, 5140,    7, 2159, 1864, 5918,    0, 2159, 5918, 1110,\n",
              "          0, 1993, 4868, 2404,   41, 1110,    0,    7, 3814, 1968,    0,\n",
              "       3524, 4868, 6479, 5025, 5025,    0, 3880,   41, 3814, 1968,    0,\n",
              "       4868, 6479, 2159,    0,    0,   41, 3814,    0, 2159, 1911, 6479,\n",
              "       2159, 5918,    0, 1993,    7, 1911, 2159,   41, 3814,    0, 2159,\n",
              "       5918, 1110,    0, 5025, 1110,    7, 1968,    0,   41, 1534,    0,\n",
              "       1993,   41, 1534, 1864,    7, 1534, 2159,    0, 5918, 1110, 1534,\n",
              "          0, 3814, 4868, 2159,    0, 1968, 4868,   41, 3814, 3410,    0,\n",
              "       2159, 5918, 1110,    0, 3410, 1911, 1110,    7, 2159,    0, 1534,\n",
              "       5025,    7, 3420, 1534, 2159,   41, 1864, 4652,    0, 5918, 1110,\n",
              "       1534,    0, 4652, 3814, 4868, 5140, 3814,    0, 3880, 4868, 1911,\n",
              "          0, 3880, 1911, 4868, 1993,    0, 1993, 4868])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrgwoguatTV9",
        "colab_type": "text"
      },
      "source": [
        "### Load this saved file to get the reviews in the IMDB dataset represented using word indexes\n",
        "\n",
        "These have been pre-calculated and saved, and will help you if your id mapping code takes too long to run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "YytGBsA6tTV9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "review_ids = np.load('idsMatrix.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "eRrWxL5gtTWA",
        "colab_type": "code",
        "outputId": "6d4ed7c7-d1a5-4110-c802-0512ff6eb215",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "review_ids.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 250)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "C5czAtOctTWE",
        "colab_type": "code",
        "outputId": "6014ecda-789e-4179-ec3e-6f00bc292c32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "review_ids[:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[174943,    152,     14, ...,      0,      0,      0],\n",
              "       [ 26494,     46, 399999, ...,   2153,    144,      7],\n",
              "       [  6520, 399999,     21, ...,      0,      0,      0],\n",
              "       [    37,     14,   2407, ...,      0,      0,      0],\n",
              "       [    37,     14,     36, ...,      0,      0,      0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "mPdeLybltTWH",
        "colab_type": "code",
        "outputId": "5076e538-a48d-4c95-f8d4-8ecc81a10aa0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_data = review_ids\n",
        "y_output = np.array(labels)\n",
        "\n",
        "vocabulary_size = len(words)\n",
        "print(vocabulary_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "400000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "FSDWqXOjtTWK",
        "colab_type": "code",
        "outputId": "bec1f356-296f-4e8f-e99e-38af13266b4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "data[3:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[u'no this is not no alice fairy tale my friends this wonderland fable is based on the true story of the gruesome bloody wonderland murders that occurred back in 80s california at the center of this bloodbath was no other than johnny wad himself yes john holmes daddy dingdong used other shotguns than his infamous 13inch milk machine besides being a legendary adult film actor holmes was as also a hardcore drug addict who befriended various hollywood junkies val kilmer was occasionally majestic as holmes but for once this holmes character did not milk it through completely the film possesses a whos who of supporting players josh lucas  dylan mcdermott as hollywood riffraffs  kate bosworth  lisa kudrow as the women in holmes life and eric bogosian as a menacing tinsletown entrepreneur these characters do play integral parts directly or indirectly in the wonderland murders out of this support group it was josh lucas who was the most fierce  impressive as the ardent ron launius lucas is gradually escalating into a major hollywood player with such charismatic turns in a beautiful mind  sweet home alabama director james cox sometime proved to be a bit of a coxsucker by displaying a vast amount of overextended scenes just like holmes famous organ holmes was eventually acquitted of the wonderland murders he died of complications from the aids virus wonderland will keep you wondering what really happened that bloody night and if holmes really laid out his weapon oops wrong holmes movie ok that is enough before i get penislized i mean penalized bye holmies  average',\n",
              " u'the invisible mouse is a delightful and different tom  jerrys cartoon it features the usual catmouse chases and battles but in a different way this time jerry accidentally falls in a bottle of invisible ink and is obviously very glad about this because he realizes that he can prepare lots of surprises for tom scare him torment him and confuse him  as much as it is weird its also very cool and funny to see what we cant see jerry invisible its amusing to see things lifting up in the air without seeing whos doing it we know who right  its like those things had a life of their own or even almost like a matter of ghosts its equally amusing to see jerry eating some candies and fruits while hes invisible i really like that instrumental music which plays when hes not visible  some of the best jokes on this short are when tom sees jerrys shadow and slams him and even when tom tries to slam him with a frying pan and jerry writes missed me i also like when jerry drinks toms chocolate milk becoming visible again and with a happy look on his face  overall this short has the basic ingredients needed for a classic cartoon humor entertainment fun and some nice artwork too']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "ffqHbPt6tTWN",
        "colab_type": "code",
        "outputId": "8fd80a23-f093-48f1-c479-66798422e9d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "x_data[3:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    37,     14,   2407, 201534,     96,  37314,    319,   7158,\n",
              "        201534,   6469,   8828,   1085,     47,   9703,     20,    260,\n",
              "            36,    455,      7,   7284,   1139,      3,  26494,   2633,\n",
              "           203,    197,   3941,  12739,    646,      7,   7284,   1139,\n",
              "             3,  11990,   7792,     46,  12608,    646,      7,   7284,\n",
              "          1139,      3,   8593,     81,  36381,    109,      3, 201534,\n",
              "          8735,    807,   2983,     34,    149,     37,    319,     14,\n",
              "           191,  31906,      6,      7,    179,    109,  15402,     32,\n",
              "            36,      5,      4,   2933,     12,    138,      6,      7,\n",
              "           523,     59,     77,      3, 201534,     96,   4246,  30006,\n",
              "           235,      3,    908,     14,   4702,   4571,     47,     36,\n",
              "        201534,   6429,    691,     34,     47,     36,  35404,    900,\n",
              "           192,     91,   4499,     14,     12,   6469,    189,     33,\n",
              "          1784,   1318,   1726,      6, 201534,    410,     41,    835,\n",
              "         10464,     19,      7,    369,      5,   1541,     36,    100,\n",
              "           181,     19,      7,    410,      0,      0,      0,      0,\n",
              "             0,      0,      0,      0,      0,      0,      0,      0,\n",
              "             0,      0,      0,      0,      0,      0,      0,      0,\n",
              "             0,      0,      0,      0,      0,      0,      0,      0,\n",
              "             0,      0,      0,      0,      0,      0,      0,      0,\n",
              "             0,      0,      0,      0,      0,      0,      0,      0,\n",
              "             0,      0,      0,      0,      0,      0,      0,      0,\n",
              "             0,      0,      0,      0,      0,      0,      0,      0,\n",
              "             0,      0,      0,      0,      0,      0,      0,      0,\n",
              "             0,      0,      0,      0,      0,      0,      0,      0,\n",
              "             0,      0,      0,      0,      0,      0,      0,      0,\n",
              "             0,      0,      0,      0,      0,      0,      0,      0,\n",
              "             0,      0,      0,      0,      0,      0,      0,      0,\n",
              "             0,      0,      0,      0,      0,      0,      0,      0,\n",
              "             0,      0,      0,      0,      0,      0,      0,      0,\n",
              "             0,      0,      0,      0,      0,      0,      0,      0,\n",
              "             0,      0],\n",
              "       [    37,     14,     36, 201534,   3682,  10464,   6469,    319,\n",
              "            20,     15,    181,    440,  32736,     73,     96,      3,\n",
              "            26,   2459,      5,   1403,     40,      7,   2219,     12,\n",
              "            15, 399999,   8900,   5141,   4620,    116, 201534,   1005,\n",
              "            67,     14,    125,      7,   7872, 344179,   2890,     63,\n",
              "            35,     77,   4039,     12,     94,     33,     51,  47268,\n",
              "            66,      7,   1594,     56,      5,     77,   3468,     12,\n",
              "            94,    965,     33,     51,    611,      4,    159, 201534,\n",
              "           927,      4,     88,    100,     34,     64,      6,     64,\n",
              "            37,     14,   1089, 201534,    626,      4,   6046,      5,\n",
              "           253,     20, 201534,   2050,     15,    219,   1250,   6469,\n",
              "           670,    119,      7,    219,    664,    296,     26,   8853,\n",
              "          1354,      4,   1823,      4, 201534,   2052,    378,   4620,\n",
              "            15, 201534,    254,   2018,      6, 201534,   1005,     34,\n",
              "        399999,      5, 399999,    150,    334,     44,   1044,    143,\n",
              "             0,      0,      0,      0,      0,      0,      0,      0,\n",
              "             0,      0,      0,      0,      0,      0,      0,      0,\n",
              "             0,      0,      0,      0,      0,      0,      0,      0,\n",
              "             0,      0,      0,      0,      0,      0,      0,      0,\n",
              "             0,      0,      0,      0,      0,      0,      0,      0,\n",
              "             0,      0,      0,      0,      0,      0,      0,      0,\n",
              "             0,      0,      0,      0,      0,      0,      0,      0,\n",
              "             0,      0,      0,      0,      0,      0,      0,      0,\n",
              "             0,      0,      0,      0,      0,      0,      0,      0,\n",
              "             0,      0,      0,      0,      0,      0,      0,      0,\n",
              "             0,      0,      0,      0,      0,      0,      0,      0,\n",
              "             0,      0,      0,      0,      0,      0,      0,      0,\n",
              "             0,      0,      0,      0,      0,      0,      0,      0,\n",
              "             0,      0,      0,      0,      0,      0,      0,      0,\n",
              "             0,      0,      0,      0,      0,      0,      0,      0,\n",
              "             0,      0,      0,      0,      0,      0,      0,      0,\n",
              "             0,      0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "AXJvkglFtTWP",
        "colab_type": "code",
        "outputId": "818c7b04-b26c-46fd-8668-ad6eb53fe96a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_output[:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enkonaCQtTWU",
        "colab_type": "text"
      },
      "source": [
        "#### Shuffle the data so the training instances are randomly fed to the RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "LdLtKhSCtTWV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(22)\n",
        "shuffle_indices = np.random.permutation(np.arange(len(x_data)))\n",
        "\n",
        "x_shuffled = x_data[shuffle_indices]\n",
        "y_shuffled = y_output[shuffle_indices]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "utHzbY3utTWY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_DATA = 5000\n",
        "TOTAL_DATA = 6000\n",
        "\n",
        "train_data = x_shuffled[:TRAIN_DATA]\n",
        "train_target = y_shuffled[:TRAIN_DATA]\n",
        "\n",
        "test_data = x_shuffled[TRAIN_DATA:TOTAL_DATA]\n",
        "test_target = y_shuffled[TRAIN_DATA:TOTAL_DATA]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6r_MdFouw93p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwoVapckxFra",
        "colab_type": "code",
        "outputId": "3a884e43-29af-4ed3-ea7e-460cdfc3cf47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "# import tensorflow.compat.v1 as tf\n",
        "# tf.disable_v2_behavior()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0329 19:35:12.563184 140190949189504 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/compat/v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "2gycCCzjtTWc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "x = tf.placeholder(tf.int32, [None, MAX_SEQUENCE_LENGTH])\n",
        "y = tf.placeholder(tf.int32, [None])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "Fvu5fm52tTWf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 25\n",
        "embedding_size = 50\n",
        "max_label = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eKwMOx8tTWj",
        "colab_type": "text"
      },
      "source": [
        "### Embeddings to represent words\n",
        "\n",
        "These embeddings have been pre-built using GloVe a word vector embedding algorithm just like word2vec. The matrix will contain 400,000 word vectors, each with a dimensionality of 50.\n",
        "\n",
        "* *saved_embeddings* This is a matrix which holds the embeddings for every word in the vocabulary. The values have been pre-loaded and were generated using the GloVe algorithm\n",
        "* *embeddings* The embeddings for the words which are input as a part of one training batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "hKQQsvM1tTWj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "saved_embeddings = np.load('wordVectors.npy')\n",
        "embeddings = tf.nn.embedding_lookup(saved_embeddings, x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xocZgRMJtTWn",
        "colab_type": "code",
        "outputId": "c2a8d183-4b80-42f9-8be9-ea8f9c589146",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "saved_embeddings"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.       ,  0.       ,  0.       , ...,  0.       ,  0.       ,\n",
              "         0.       ],\n",
              "       [ 0.013441 ,  0.23682  , -0.16899  , ..., -0.56657  ,  0.044691 ,\n",
              "         0.30392  ],\n",
              "       [ 0.15164  ,  0.30177  , -0.16763  , ..., -0.35652  ,  0.016413 ,\n",
              "         0.10216  ],\n",
              "       ...,\n",
              "       [-0.51181  ,  0.058706 ,  1.0913   , ..., -0.25003  , -1.125    ,\n",
              "         1.5863   ],\n",
              "       [-0.75898  , -0.47426  ,  0.4737   , ...,  0.78954  , -0.014116 ,\n",
              "         0.6448   ],\n",
              "       [-0.79149  ,  0.86617  ,  0.11998  , ..., -0.29996  , -0.0063003,\n",
              "         0.3954   ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "u65DtLfUtTWs",
        "colab_type": "code",
        "outputId": "ce74d195-0c6e-4e07-d9ac-f0656e3f63b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "embeddings"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'embedding_lookup/Identity:0' shape=(?, 250, 50) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3-NNddizDxF",
        "colab_type": "code",
        "outputId": "6ba50674-b583-4e85-adba-bdfa892a7548",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        }
      },
      "source": [
        "# resolver = tf.contrib.cluster_resolver.TPUClusterResolver('grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "# tf.contrib.distribute.initialize_tpu_system(resolver)\n",
        "# strategy = tf.contrib.distribute.TPUStrategy(resolver)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0329 19:58:04.787231 139956296599424 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "W0329 19:58:06.962148 139956296599424 module_wrapper.py:139] From /tensorflow-1.15.2/python2.7/tensorflow_estimator/python/estimator/api/_v1/estimator/__init__.py:12: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-1ee083519346>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_resolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPUClusterResolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'grpc://'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'COLAB_TPU_ADDR'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_tpu_system\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPUStrategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python2.7/UserDict.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__missing__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__missing__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__delitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'COLAB_TPU_ADDR'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "EbWVarKUtTWv",
        "colab_type": "code",
        "outputId": "db6759ef-783b-4fd8-d85d-03d9b11f971a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "lstmCell = tf.contrib.rnn.BasicLSTMCell(embedding_size)\n",
        "lstmCell = tf.contrib.rnn.DropoutWrapper(cell=lstmCell, output_keep_prob=0.75)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0329 19:58:25.448853 139956296599424 deprecation.py:323] From <ipython-input-41-41dee28f93a4>:1: __init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrYy9yOztTW0",
        "colab_type": "text"
      },
      "source": [
        "### Results from an RNN of LSTM cells\n",
        "\n",
        "(ouput, (**final_state**, other_state_info))\n",
        "\n",
        "We're interested in the final state of this RNN because those are the encodings we feed into the prediction layer of our neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "f7-zjmx6tTW1",
        "colab_type": "code",
        "outputId": "1ab85ced-7e74-4c2d-8d71-7ebbce42b74a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        }
      },
      "source": [
        "_, (encoding, _) = tf.nn.dynamic_rnn(lstmCell, embeddings, dtype=tf.float32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0329 19:58:31.582591 139956296599424 deprecation.py:323] From <ipython-input-42-828d6e9e5bdf>:1: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "W0329 19:58:31.689204 139956296599424 deprecation.py:323] From /tensorflow-1.15.2/python2.7/tensorflow_core/python/ops/rnn_cell_impl.py:735: add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "W0329 19:58:31.702788 139956296599424 deprecation.py:506] From /tensorflow-1.15.2/python2.7/tensorflow_core/python/ops/rnn_cell_impl.py:739: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "LzmqE-gotTW6",
        "colab_type": "code",
        "outputId": "30783d14-c09a-4908-f03f-a7b1dbe646eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "encoding"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'rnn/while/Exit_3:0' shape=(?, 50) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xTv17VNtTW9",
        "colab_type": "text"
      },
      "source": [
        "#### A densely connected prediction layer\n",
        "\n",
        "* *activation=None* because the activation will be part of the tf.nn.sparse_softmax_cross_entropy_with_logits\n",
        "* *cross_entropy* the loss function for probability distributions\n",
        "* *max_label* the number of outputs of the prediction layer, here is 2, positive or negative"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "cbIg1GUStTW-",
        "colab_type": "code",
        "outputId": "6130e5fb-0643-424d-9d04-9feb6df41d47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "logits = tf.layers.dense(encoding, max_label, activation=None)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0329 19:58:37.929779 139956296599424 deprecation.py:323] From <ipython-input-44-30584d302e79>:1: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "W0329 19:58:37.932073 139956296599424 deprecation.py:323] From /tensorflow-1.15.2/python2.7/tensorflow_core/python/layers/core.py:187: apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "wkzE0oxqtTXC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y)\n",
        "loss = tf.reduce_mean(cross_entropy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMKuZcGztTXF",
        "colab_type": "text"
      },
      "source": [
        "#### Find the output with the highest probability and compare against the true label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "NlC18fNdtTXH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction = tf.equal(tf.argmax(logits, 1), tf.cast(y, tf.int64))\n",
        "accuracy = tf.reduce_mean(tf.cast(prediction, tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "cojI5o_DtTXK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.train.AdamOptimizer(0.01)\n",
        "train_step = optimizer.minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjcLjW5xtTXN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_epochs = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "NScBUxDStTXT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "GLJqMB7rtTXW",
        "colab_type": "code",
        "outputId": "36118d07-9748-41ab-8a1f-a6f405c1cd32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        }
      },
      "source": [
        "with tf.Session() as session:\n",
        "    init.run()\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        \n",
        "        num_batches = int(len(train_data) // batch_size) + 1\n",
        "        \n",
        "        for i in range(num_batches):\n",
        "            # Select train data\n",
        "            min_ix = i * batch_size\n",
        "            max_ix = np.min([len(train_data), ((i+1) * batch_size)])\n",
        "\n",
        "            x_train_batch = train_data[min_ix:max_ix]\n",
        "            y_train_batch = train_target[min_ix:max_ix]\n",
        "            \n",
        "            train_dict = {x: x_train_batch, y: y_train_batch}\n",
        "            \n",
        "            \n",
        "            session.run(train_step, feed_dict=train_dict)\n",
        "            \n",
        "            train_loss, train_acc = session.run([loss, accuracy], feed_dict=train_dict)\n",
        "\n",
        "        test_dict = {x: test_data, y: test_target}\n",
        "        test_loss, test_acc = session.run([loss, accuracy], feed_dict=test_dict)    \n",
        "        print('Epoch: {}, Test Loss: {:.2}, Test Acc: {:.5}'.format(epoch + 1, test_loss, test_acc)) \n",
        "        saver = tf.train.Saver()\n",
        "        save_path = saver.save(session, \"TessorFlowModel.ckpt\")\n",
        "        print(\"Model saved in path: %s\" % save_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, Test Loss: 0.7, Test Acc: 0.494\n",
            "Model saved in path: TessorFlowModel.ckpt\n",
            "Epoch: 2, Test Loss: 0.68, Test Acc: 0.544\n",
            "Model saved in path: TessorFlowModel.ckpt\n",
            "Epoch: 3, Test Loss: 0.74, Test Acc: 0.489\n",
            "Model saved in path: TessorFlowModel.ckpt\n",
            "Epoch: 4, Test Loss: 0.72, Test Acc: 0.49\n",
            "Model saved in path: TessorFlowModel.ckpt\n",
            "Epoch: 5, Test Loss: 0.71, Test Acc: 0.485\n",
            "Model saved in path: TessorFlowModel.ckpt\n",
            "Epoch: 6, Test Loss: 0.7, Test Acc: 0.506\n",
            "Model saved in path: TessorFlowModel.ckpt\n",
            "Epoch: 7, Test Loss: 0.71, Test Acc: 0.516\n",
            "Model saved in path: TessorFlowModel.ckpt\n",
            "Epoch: 8, Test Loss: 0.69, Test Acc: 0.543\n",
            "Model saved in path: TessorFlowModel.ckpt\n",
            "Epoch: 9, Test Loss: 0.67, Test Acc: 0.54\n",
            "Model saved in path: TessorFlowModel.ckpt\n",
            "Epoch: 10, Test Loss: 0.67, Test Acc: 0.547\n",
            "Model saved in path: TessorFlowModel.ckpt\n",
            "Epoch: 11, Test Loss: 0.68, Test Acc: 0.55\n",
            "Model saved in path: TessorFlowModel.ckpt\n",
            "Epoch: 12, Test Loss: 0.68, Test Acc: 0.549\n",
            "Model saved in path: TessorFlowModel.ckpt\n",
            "Epoch: 13, Test Loss: 0.71, Test Acc: 0.549\n",
            "Model saved in path: TessorFlowModel.ckpt\n",
            "Epoch: 14, Test Loss: 0.72, Test Acc: 0.554\n",
            "Model saved in path: TessorFlowModel.ckpt\n",
            "Epoch: 15, Test Loss: 0.76, Test Acc: 0.556\n",
            "Model saved in path: TessorFlowModel.ckpt\n",
            "Epoch: 16, Test Loss: 0.8, Test Acc: 0.54\n",
            "Model saved in path: TessorFlowModel.ckpt\n",
            "Epoch: 17, Test Loss: 0.75, Test Acc: 0.55\n",
            "Model saved in path: TessorFlowModel.ckpt\n",
            "Epoch: 18, Test Loss: 0.82, Test Acc: 0.548\n",
            "Model saved in path: TessorFlowModel.ckpt\n",
            "Epoch: 19, Test Loss: 0.84, Test Acc: 0.555\n",
            "Model saved in path: TessorFlowModel.ckpt\n",
            "Epoch: 20, Test Loss: 0.86, Test Acc: 0.549\n",
            "Model saved in path: TessorFlowModel.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "oe7Bg-nLtTXa",
        "colab_type": "code",
        "outputId": "b5ecf4f0-dc08-48e1-9d71-aacbdf5ca585",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        }
      },
      "source": [
        "saver = tf.train.Saver()\n",
        "save_path = saver.save(session, \"TessorFlowModel.ckpt\")\n",
        "print(\"Model saved in path: %s\" % save_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR! Session/line number was not unique in database. History logging moved to new session 60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-9ea23b0e8448>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TessorFlowModel.ckpt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tensorflow-1.15.2/python2.7/tensorflow_core/python/training/saver.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state, strip_default_attrs, save_debug_info)\u001b[0m\n\u001b[1;32m   1174\u001b[0m           model_checkpoint_path = sess.run(\n\u001b[1;32m   1175\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_tensor_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m               {self.saver_def.filename_tensor_name: checkpoint_file})\n\u001b[0m\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0mmodel_checkpoint_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python2.7/tensorflow_core/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python2.7/tensorflow_core/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1101\u001b[0m     \u001b[0;31m# Check session.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Attempted to use a closed Session.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m       raise RuntimeError('The Session graph is empty.  Add operations to the '\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Attempted to use a closed Session."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "g84K71XNtTXe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "0SBk6paAtTXj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}